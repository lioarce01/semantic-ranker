# üìö Glosario de Machine Learning para Evaluaci√≥n de Modelos

## üîç T√©rminos B√°sicos de Entrenamiento

### **Loss (P√©rdida)**
**Qu√© es**: Medida num√©rica de qu√© tan mal est√° prediciendo el modelo. Es como un "puntaje de error".

**C√≥mo interpretarlo**:
- `Loss = 0.0`: Predicciones perfectas (ideal pero imposible)
- `Loss = 0.1-0.5`: Bueno para clasificaci√≥n binaria
- `Loss > 1.0`: Modelo aprendiendo o datos problem√°ticos
- `Loss bajando`: ‚úÖ Modelo aprendiendo
- `Loss subiendo`: ‚ùå Problema (overfitting o datos malos)

**Ejemplo del entrenamiento**:
```
Epoch 1: Train Loss = 0.2212 (malo, aprendiendo)
Epoch 3: Train Loss = 0.0119 (muy bueno, convergi√≥)
```

### **Epoch (√âpoca)**
**Qu√© es**: Una pasada completa por todo el dataset de entrenamiento.

**C√≥mo interpretarlo**:
- **1 epoch**: Modelo vio cada ejemplo 1 vez
- **3 epochs**: Modelo vio cada ejemplo 3 veces
- **M√°s epochs**: M√°s aprendizaje, pero riesgo de overfitting

### **Batch Size (Tama√±o de Lote)**
**Qu√© es**: Cantidad de ejemplos que procesa el modelo antes de actualizar sus par√°metros.

**C√≥mo interpretarlo**:
- `batch_size=8`: ‚úÖ Peque√±o, aprendizaje estable, usa menos memoria
- `batch_size=32`: ‚öñÔ∏è Balance, buen compromiso
- `batch_size=128`: ‚ö° R√°pido pero puede ser inestable

### **Learning Rate (Tasa de Aprendizaje)**
**Qu√© es**: Qu√© tan grande es cada "paso" que da el modelo para aprender.

**C√≥mo interpretarlo**:
- `1e-5` (0.00001): ‚úÖ Muy peque√±o, aprendizaje lento pero estable
- `2e-5` (0.00002): ‚úÖ Valor t√≠pico para fine-tuning
- `1e-3` (0.001): ‚ùå Muy grande, puede "saltar" la soluci√≥n √≥ptima

**Del entrenamiento**:
```
1.7983193277310925e-05  ‚Üí 1.8e-5 (√≥ptimo)
9.579831932773111e-06   ‚Üí 9.6e-6 (m√°s peque√±o, fine-tuning)
```

## üìä M√©tricas de Evaluaci√≥n

### **Train Loss vs Validation Loss**
**Qu√© miden**:
- **Train Loss**: Qu√© tan bien aprende el modelo con datos de entrenamiento
- **Validation Loss**: Qu√© tan bien generaliza a datos nuevos

**C√≥mo interpretarlo**:
```
‚úÖ BUENO:     Train: 0.012, Val: 0.021 (aprendi√≥ y generaliza)
‚ö†Ô∏è  OVERFIT:  Train: 0.001, Val: 0.200 (memoriz√≥, no generaliza)
‚ùå  UNDERFIT: Train: 0.500, Val: 0.450 (no aprendi√≥ suficiente)
```

### **Convergencia (Convergence)**
**Qu√© es**: Cuando el modelo deja de mejorar significativamente.

**Indicadores**:
- ‚úÖ Loss estable por 2-3 epochs
- ‚úÖ Train y validation loss cercanos
- ‚ùå Loss oscilando mucho
- ‚ùå Validation loss subiendo

### **Overfitting (Sobreajuste)**
**Qu√© es**: Modelo memoriza datos de entrenamiento pero falla en datos nuevos.

**S√≠ntomas**:
- Train Loss muy bajo (< 0.01)
- Validation Loss alto (> 0.1)
- Diferencia grande entre train/val loss

**Soluci√≥n**: M√°s datos, regularizaci√≥n, early stopping.

### **Underfitting (Subajuste)**
**Qu√© es**: Modelo no aprende lo suficiente de los datos.

**S√≠ntomas**:
- Train Loss alto (> 0.5)
- Validation Loss similar al train
- Modelo predice igual que al azar

**Soluci√≥n**: M√°s epochs, learning rate m√°s alto, modelo m√°s complejo.

## üèóÔ∏è Arquitectura del Modelo

### **Cross-Encoder**
**Qu√© es**: Modelo que procesa query + documento juntos para predecir relevancia.

**Ventajas**:
- ‚úÖ Muy preciso para ranking
- ‚úÖ Entiende contexto completo
- ‚ùå Lento (procesa cada par por separado)

### **DistilBERT**
**Qu√© es**: Versi√≥n "destilada" (m√°s peque√±a) de BERT.

**Caracter√≠sticas**:
- 66M par√°metros (vs 110M de BERT-base)
- 40% m√°s r√°pido
- 97% accuracy de BERT
- Perfecto para fine-tuning

### **LoRA (Low-Rank Adaptation)**
**Qu√© es**: T√©cnica para fine-tuning eficiente que solo entrena pocos par√°metros.

**Beneficios**:
- ‚úÖ 10x menos memoria
- ‚úÖ Entrenamiento m√°s r√°pido
- ‚úÖ Mismo rendimiento
- ‚úÖ Compatible con modelos grandes

## üìà Rendimiento y Benchmarks

### **NDCG@k (Normalized Discounted Cumulative Gain)**
**Qu√© mide**: Calidad del ranking (qu√© tan buenos son los top-k resultados).

**Interpretaci√≥n**:
- `NDCG@10 = 0.85`: ‚úÖ Excelente (85% de resultados perfectos)
- `NDCG@10 = 0.60`: ‚öñÔ∏è Bueno
- `NDCG@10 = 0.30`: ‚ùå Malo

### **MRR@k (Mean Reciprocal Rank)**
**Qu√© mide**: Posici√≥n del primer resultado relevante.

**Interpretaci√≥n**:
- `MRR@10 = 0.90`: ‚úÖ Primer resultado relevante en top-1 promedio
- `MRR@10 = 0.50`: ‚öñÔ∏è Primer resultado relevante en top-2 promedio

### **Latency (Latencia)**
**Qu√© mide**: Tiempo que tarda en procesar una query.

**Objetivos t√≠picos**:
- ‚úÖ `< 50ms`: Excelente para b√∫squeda en tiempo real
- ‚ö†Ô∏è `50-200ms`: Aceptable
- ‚ùå `> 500ms`: Demasiado lento

## üîß Configuraci√≥n del Entrenamiento

### **Gradient Accumulation**
**Qu√© es**: Acumulador gradientes antes de actualizar par√°metros.

**Cu√°ndo usar**:
- Batch size peque√±o por limitaci√≥n de memoria
- Simula batch size m√°s grande

### **Mixed Precision (FP16)**
**Qu√© es**: Entrenamiento con n√∫meros de 16 bits en lugar de 32.

**Beneficios**:
- ‚úÖ 2x m√°s r√°pido
- ‚úÖ Usa menos memoria
- ‚úÖ Mismo accuracy

### **Early Stopping**
**Qu√© es**: Detiene entrenamiento cuando validation loss deja de bajar.

**Configuraci√≥n t√≠pica**:
- Patience: 3-5 epochs
- Min delta: 0.001
- Restaura mejor modelo

## üìä Interpretaci√≥n de Logs

### **Training Progress**
```
Epoch 1/3
Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [04:38<00:00, 3.17s/it, loss=0.0931]
INFO: Epoch 1 completed. Avg loss: 0.2212
```

**Qu√© significa**:
- `88/88`: 88 batches procesados (100%)
- `3.17s/it`: 3.17 segundos por batch
- `loss=0.0931`: Loss del √∫ltimo batch
- `Avg loss: 0.2212`: Loss promedio de toda la epoch

### **Validation Check**
```
INFO: Step 100: val_loss = 0.0330
INFO: Saved best model (val_loss=0.0330)
```

**Qu√© significa**:
- Cada 100 steps: eval√∫a en validation set
- `val_loss = 0.0330`: Performance en datos no vistos
- Guarda modelo si es el mejor hasta ahora

## üéØ Checklist para Evaluar Entrenamiento

### ‚úÖ **Entrenamiento Saludable**
- [ ] Loss bajando consistentemente
- [ ] Train y validation loss convergiendo
- [ ] No overfitting (val_loss no sube mucho)
- [ ] Learning rate decay apropiado
- [ ] Modelo converge en < 10 epochs

### ‚ö†Ô∏è **Se√±ales de Problema**
- [ ] Loss oscilando mucho
- [ ] Validation loss subiendo
- [ ] Train loss muy bajo, val loss alto
- [ ] Modelo no converge despu√©s de 20 epochs

### üîß **Optimizaciones**
- [ ] Usar GPU si disponible
- [ ] Batch size √≥ptimo para memoria
- [ ] Learning rate decay
- [ ] Early stopping
- [ ] Mixed precision (FP16)

## üìù Resumen Ejecutivo

**Para evaluar un modelo, mira:**

1. **Loss bajando** ‚Üí ‚úÖ Aprendiendo
2. **Train ‚âà Validation** ‚Üí ‚úÖ Generalizando
3. **Convergencia** ‚Üí ‚úÖ Listo para usar
4. **Sin overfitting** ‚Üí ‚úÖ Confiable

**M√©tricas clave del √∫ltimo entrenamiento:**
- **Train Loss**: `0.0119` (muy bueno, < 0.05)
- **Val Loss**: `0.0209` (excelente, cercano al train)
- **Convergencia**: ‚úÖ Estable en 3 epochs
- **Overfitting**: ‚úÖ No presente

¬°El modelo est√° **perfectamente entrenado**! üéâ

## üéØ **M√©tricas Avanzadas de Evaluaci√≥n (Reranking)**

### **NDCG@10 (Normalized Discounted Cumulative Gain)**
**Qu√© es**: La m√©trica m√°s importante para evaluar rerankers. Mide calidad del ranking considerando posici√≥n Y relevancia.

**C√≥mo interpretarlo**:
- `NDCG@10 = 1.0`: ‚úÖ Ranking perfecto (ideal)
- `NDCG@10 ‚â• 0.85`: ‚úÖ **Excelente** (state-of-the-art)
- `NDCG@10 ‚â• 0.80`: ‚úÖ **Muy bueno** (competitivo)
- `NDCG@10 ‚â• 0.75`: ‚öñÔ∏è **Bueno** (√∫til en producci√≥n)
- `NDCG@10 ‚â• 0.70`: ‚ö†Ô∏è **Aceptable** (mejorable)
- `NDCG@10 < 0.70`: ‚ùå **Necesita mejoras**

**Ejemplos reales**:
- `0.866`: BGE-Reranker-v2.0 (l√≠der actual)
- `0.842`: FlashRank (muy competitivo)
- `0.582`: Tu modelo actual (necesita mejoras)

### **MRR@10 (Mean Reciprocal Rank)**
**Qu√© es**: Mide qu√© tan temprano aparece el primer documento relevante en los resultados.

**C√≥mo interpretarlo**:
- `MRR@10 = 1.0`: ‚úÖ Primer resultado relevante (perfecto)
- `MRR@10 ‚â• 0.85`: ‚úÖ **Excelente**
- `MRR@10 ‚â• 0.70`: ‚öñÔ∏è **Bueno**
- `MRR@10 < 0.50`: ‚ùå **Necesita mejoras**

**F√≥rmula**: `MRR = 1/posici√≥n_del_primer_relevante`
- Si relevante est√° en posici√≥n 3 ‚Üí MRR = 1/3 = 0.33

### **MAP@100 (Mean Average Precision)**
**Qu√© es**: Precisi√≥n promedio considerando todos los documentos relevantes encontrados.

**C√≥mo interpretarlo**:
- `MAP@100 ‚â• 0.80`: ‚úÖ **Excelente**
- `MAP@100 ‚â• 0.70`: ‚öñÔ∏è **Bueno**
- Mide tanto precisi√≥n como exhaustividad

### **Recall@100**
**Qu√© es**: Fracci√≥n de documentos relevantes encontrados en el top-100.

**C√≥mo interpretarlo**:
- `Recall@100 ‚â• 0.90`: ‚úÖ **Excelente** (encuentra casi todos)
- `Recall@100 ‚â• 0.80`: ‚öñÔ∏è **Bueno**
- Mide capacidad de encontrar documentos relevantes

## üèÜ **Modelos State-of-the-Art**

### **BGE (BAAI General Embeddings)**
- **Tipo**: Embeddings densos para retrieval
- **Mejores modelos**: BGE-M3, BGE-Reranker-v2.0
- **NDCG@10 t√≠pico**: 0.81-0.87
- **Ventaja**: R√°pido para b√∫squeda inicial

### **FlashRank**
- **Tipo**: Cross-encoder reranker
- **NDCG@10**: ~0.84
- **Latencia**: 10-50ms por query
- **Ventaja**: Muy eficiente

### **MonoT5**
- **Tipo**: Cross-encoder basado en T5
- **NDCG@10**: ~0.81
- **Ventaja**: Arquitectura probada

## üîß **T√©cnicas de Mejora**

### **Retrain (Reentrenamiento)**
**Qu√© es**: Continuar entrenando un modelo existente con m√°s datos.

**Cu√°ndo usar**:
- ‚úÖ Modelo funciona pero necesita m√°s datos
- ‚úÖ Arquitectura correcta, falta entrenamiento
- ‚úÖ Menos riesgoso que reentrenar desde cero

**Ejemplo**:
```bash
python cli/retrain.py --samples 2000 --epochs 3 --learning-rate 2e-5
```

### **Hard Negative Mining**
**Qu√© es**: Seleccionar ejemplos dif√≠ciles (negativos que el modelo confunde) para entrenamiento.

**Beneficio**: Mejora robustez del modelo (+0.05-0.10 NDCG)

### **Data Augmentation**
**Qu√© es**: Crear variaciones de los datos de entrenamiento.

**T√©cnicas**:
- Query expansion
- Document paraphrasing
- Multi-task learning

## üìä **Benchmarks de Referencia**

### **MS MARCO**
- **Tipo**: QA general en ingl√©s
- **Tama√±o**: ~800k queries
- **√ötil para**: Evaluaci√≥n general de rerankers

### **BEIR (Benchmarking IR)**
- **Tipo**: 18 datasets especializados
- **Dominios**: Biomedicina, noticias, cient√≠fico, etc.
- **√ötil para**: Evaluaci√≥n en dominios espec√≠ficos

### **TREC-COVID**
- **Tipo**: B√∫squeda m√©dica
- **√ötil para**: Evaluaci√≥n en dominio m√©dico

## üéØ **Interpretaci√≥n de Resultados**

### **Tu Modelo Actual**
- **NDCG@10 = 0.5829**: ‚ùå Necesita mejoras significativas
- **Estado**: Funcional pero bajo rendimiento
- **Posici√≥n**: Top 50% de modelos publicados

### **Metas Realistas**
- **Versi√≥n mejorada**: NDCG@10 ‚â• 0.70
- **Competitivo**: NDCG@10 ‚â• 0.80
- **State-of-the-art**: NDCG@10 ‚â• 0.85

### **Plan de Mejora**
1. **Retrain con m√°s datos** (+0.05-0.10)
2. **Hard negatives** (+0.03-0.08)
3. **Mejor arquitectura** (+0.05-0.15)
4. **Fine-tuning avanzado** (+0.02-0.05)

¬°El glosario est√° **actualizado con m√©tricas avanzadas**! üìö‚ú®
