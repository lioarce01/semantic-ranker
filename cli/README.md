# Command Line Interface

Interfaz de lÃ­nea de comandos con responsabilidades separadas para semantic-ranker.

## ğŸ›ï¸ Sistema de ConfiguraciÃ³n

Todos los comandos soportan configuraciÃ³n centralizada con perfiles YAML:

```bash
# Usar perfil de configuraciÃ³n
python cli/train.py --config-profile quick_test

# Cargar config personalizado
python cli/train.py --config configs/my_experiment.yaml

# Sobrescribir valores especÃ­ficos
python cli/train.py --config-profile default --epochs 5 --learning-rate 1e-5
```

**Perfiles disponibles** (en `configs/`):
- `default.yaml` - ConfiguraciÃ³n estÃ¡ndar
- `quick_test.yaml` - Testing rÃ¡pido (1 Ã©poca, 100 muestras)
- `full_training.yaml` - Entrenamiento completo (10 Ã©pocas, negativos difÃ­ciles)
- `lora_training.yaml` - ConfiguraciÃ³n especÃ­fica para LoRA
- `quantum_training.yaml` - Quantum fine-tuning
- `retrain.yaml` - Reentrenamiento (LR bajo, preservaciÃ³n de conocimiento)

## ğŸ“‹ Comandos Disponibles

### ğŸš€ `train.py` - Entrenamiento
**Responsabilidad**: Solo entrenamiento de modelos.

```bash
# Entrenamiento bÃ¡sico
python cli/train.py --dataset msmarco --epochs 3 --batch-size 16

# Con perfil de configuraciÃ³n
python cli/train.py --config-profile full_training --dataset msmarco

# Con LoRA (eficiente en memoria)
python cli/train.py --config-profile lora_training --use-lora
```

**ParÃ¡metros principales:**
- `--config-profile` / `--config`: Cargar configuraciÃ³n desde YAML
- `--dataset`: Dataset de entrenamiento (msmarco o archivos en datasets/)
- `--model-name`: Modelo base (default: bert-base-uncased)
- `--epochs`: NÃºmero de epochs
- `--batch-size`: TamaÃ±o del batch
- `--learning-rate`: Tasa de aprendizaje
- `--use-lora`: Usar LoRA para entrenamiento eficiente

### ğŸ“Š `eval.py` - EvaluaciÃ³n
**Responsabilidad**: Solo evaluaciÃ³n del mejor modelo entrenado.

```bash
# EvaluaciÃ³n bÃ¡sica
python cli/eval.py --dataset msmarco --samples 100

# EvaluaciÃ³n optimizada (3-5x mÃ¡s rÃ¡pido)
python cli/eval.py --dataset msmarco --samples 1000 --query-batch-size 8

# Con perfil de configuraciÃ³n
python cli/eval.py --config-profile default --samples 500
```

**ParÃ¡metros principales:**
- `--config-profile` / `--config`: Cargar configuraciÃ³n desde YAML
- `--dataset`: Dataset para evaluaciÃ³n
- `--samples`: NÃºmero de muestras
- `--query-batch-size`: Procesar N queries simultÃ¡neamente (default: 8, optimizaciÃ³n de velocidad)

**CaracterÃ­sticas:**
- Busca automÃ¡ticamente el mejor modelo en `./models/`
- EvalÃºa en dataset separado (nunca visto en entrenamiento)
- Calcula mÃ©tricas IR: NDCG, MRR, MAP, Hit Rate
- **Nuevo**: Batch query processing para 3-5x speedup

### ğŸ§ª `test.py` - Testing
**Responsabilidad**: Solo testing/inferencia del mejor modelo.

```bash
# Usar queries reales del dataset MS MARCO
python cli/test.py --domain msmarco

# Usar queries completamente frescas de MS MARCO
python cli/test.py --domain msmarco_fresh

# Usar queries de ejemplo por dominio
python cli/test.py --domain medical
python cli/test.py --domain legal
python cli/test.py --domain technical

# Usar tus propias queries
python cli/test.py --queries "Â¿QuÃ© es machine learning?" "Â¿CÃ³mo funciona Python?"

# Con perfil de configuraciÃ³n
python cli/test.py --config-profile default --domain technical
```

**CaracterÃ­sticas:**
- **msmarco**: Queries reales del mismo 15% usado por eval (âš ï¸ no completamente fresco)
- **msmarco_fresh**: Queries completamente diferentes (recomendado para testing honesto)
- **Dominios**: Queries de ejemplo especializadas (medical, legal, technical)
- **Custom**: Tus propias queries especÃ­ficas
- Muestra ranking de documentos por relevancia en tiempo real

### ğŸ”„ `retrain.py` - Reentrenamiento
**Responsabilidad**: Solo reentrenamiento del mejor modelo.

```bash
# Reentrenamiento estÃ¡ndar
python cli/retrain.py --dataset legal_spanish --epochs 2 --learning-rate 1e-5

# Reentrenamiento con Quantum Resonance Fine-Tuning
python cli/retrain.py --dataset legal_spanish --epochs 2 --quantum-mode

# Con perfil de configuraciÃ³n (incluye quantum_mode)
python cli/retrain.py --config-profile retrain --dataset custom_data
```

**ParÃ¡metros principales:**
- `--config-profile` / `--config`: Cargar configuraciÃ³n desde YAML
- `--dataset`: Dataset adicional para reentrenamiento
- `--epochs`: NÃºmero de Ã©pocas adicionales (default: 2)
- `--learning-rate`: Tasa de aprendizaje (default: 1e-5, mÃ¡s bajo que training)
- `--samples`: NÃºmero de muestras adicionales
- `--quantum-mode`: **Nuevo** - Habilita quantum resonance fine-tuning (preservaciÃ³n de conocimiento)

**CaracterÃ­sticas:**
- Carga automÃ¡ticamente el mejor modelo
- Agrega datos adicionales para fine-tuning
- Learning rate mÃ¡s bajo para no "olvidar" lo aprendido
- **Quantum mode**: Preserva conocimiento existente con principios cuÃ¡nticos (ver configs/retrain.yaml)

### ğŸ§¬ `quantum_train.py` - Quantum Training
**Responsabilidad**: Entrenamiento con Quantum Resonance.

```bash
# Quantum training desde cero
python cli/quantum_train.py --dataset msmarco --epochs 3

# Con configuraciÃ³n quantum
python cli/quantum_train.py --config-profile quantum_training
```

**CaracterÃ­sticas:**
- Entrenamiento con principios de resonancia cuÃ¡ntica
- Mejor manejo de ejemplos difÃ­ciles
- Patrones de coherencia en predicciones

### ğŸŒŠ `quantum_retrain.py` - Quantum Retraining
**Responsabilidad**: Reentrenamiento especializado con quantum principles.

```bash
# Quantum retraining con anÃ¡lisis de resonancia
python cli/quantum_retrain.py --dataset new_domain --analyze-existing

# Configurar pesos de preservaciÃ³n
python cli/quantum_retrain.py --dataset new_domain \
  --preserve-knowledge 0.4 --resonance-alignment 0.3
```

**ParÃ¡metros quantum:**
- `--quantum-mode`: Modo quantum (adaptation, resonance, entanglement)
- `--preserve-knowledge`: Peso para preservaciÃ³n de conocimiento (0.0-1.0)
- `--resonance-alignment`: Peso para alineaciÃ³n de resonancia (0.0-1.0)
- `--analyze-existing`: Analizar patrones de resonancia antes de reentrenar

### ğŸ“Š `batch_eval.py` - Batch Evaluation
**Responsabilidad**: EvaluaciÃ³n en batch de mÃºltiples datasets/configuraciones.

```bash
# Evaluar mÃºltiples datasets
python cli/batch_eval.py --datasets msmarco legal medical

# Con configuraciÃ³n
python cli/batch_eval.py --config-profile default --datasets msmarco custom
```

**CaracterÃ­sticas:**
- EvalÃºa mÃºltiples datasets en una sola ejecuciÃ³n
- Compara rendimiento entre datasets
- Genera reporte comparativo

## ğŸ¯ Principio de Responsabilidad Ãšnica

Cada comando tiene una sola responsabilidad clara:

| Comando | Entrada | Proceso | Salida | Nunca hace |
|---------|---------|---------|--------|------------|
| `train.py` | Dataset crudo | Entrenamiento | Modelo entrenado | EvaluaciÃ³n |
| `eval.py` | Modelo entrenado | EvaluaciÃ³n | MÃ©tricas IR | Entrenamiento |
| `test.py` | Modelo entrenado | Inference | Rankings | Entrenamiento |
| `retrain.py` | Modelo + datos | Fine-tuning | Modelo mejorado | EvaluaciÃ³n nueva |
| `quantum_train.py` | Dataset crudo | Quantum training | Modelo quantum | EvaluaciÃ³n |
| `quantum_retrain.py` | Modelo + datos | Quantum adaptation | Modelo adaptado | EvaluaciÃ³n nueva |
| `batch_eval.py` | MÃºltiples datasets | Batch evaluation | Reporte comparativo | Entrenamiento |

## ğŸ”„ Flujos de Trabajo

### Workflow BÃ¡sico
```bash
# 1. Entrenar modelo
python cli/train.py --config-profile default --dataset msmarco

# 2. Evaluar rendimiento (optimizado)
python cli/eval.py --dataset msmarco --query-batch-size 8

# 3. Probar con queries reales
python cli/test.py --domain technical

# 4. Reentrenar si es necesario
python cli/retrain.py --dataset legal_spanish --epochs 2
```

### Workflow con Quantum Mode
```bash
# 1. Entrenar con quantum resonance
python cli/quantum_train.py --config-profile quantum_training

# 2. Evaluar
python cli/eval.py --dataset msmarco

# 3. Reentrenar preservando conocimiento
python cli/retrain.py --dataset new_domain --quantum-mode --epochs 2
```

### Workflow de Testing RÃ¡pido
```bash
# Usar perfil quick_test para iteraciÃ³n rÃ¡pida
python cli/train.py --config-profile quick_test
python cli/eval.py --config-profile quick_test
```

## ğŸ“‚ Estructura de Modelos

Los comandos crean esta estructura automÃ¡ticamente:

```
models/
â”œâ”€â”€ trained_model/              # De train.py
â”‚   â”œâ”€â”€ best/                   # Mejor checkpoint
â”‚   â”‚   â”œâ”€â”€ model.safetensors  # O adapter_model.safetensors (LoRA)
â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â””â”€â”€ model_config.json
â”‚   â”œâ”€â”€ final/                  # Ãšltimo checkpoint
â”‚   â”œâ”€â”€ epoch_1/, epoch_2/      # Checkpoints intermedios
â”‚   â””â”€â”€ training_history.json
â”œâ”€â”€ trained_model_retrained/    # De retrain.py
â”‚   â”œâ”€â”€ best/
â”‚   â””â”€â”€ ...
â””â”€â”€ trained_model_quantum_retrained/  # De quantum_retrain.py
    â”œâ”€â”€ best/
    â””â”€â”€ ...
```

## âš™ï¸ ConfiguraciÃ³n por Defecto

- **Modelo**: `bert-base-uncased` (balance rendimiento/velocidad)
- **Batch size**: 16 (equilibrio memoria/velocidad)
- **Learning rate**: 2e-5 (Ã³ptimo para fine-tuning)
- **Dataset**: msmarco (puedes cambiar a cualquier .json en datasets/)
- **EvaluaciÃ³n**: Siempre busca el mejor modelo automÃ¡ticamente
- **Query batch size**: 8 (evaluaciÃ³n optimizada)

## ğŸš€ Optimizaciones de Performance

### EvaluaciÃ³n RÃ¡pida
```bash
# 3-5x mÃ¡s rÃ¡pido con batch processing
python cli/eval.py --samples 1000 --query-batch-size 8
```

### Entrenamiento Eficiente con LoRA
```bash
# Reduce uso de memoria ~3x
python cli/train.py --config-profile lora_training --use-lora
```

### Testing RÃ¡pido
```bash
# 1 Ã©poca, 100 muestras para validaciÃ³n rÃ¡pida
python cli/train.py --config-profile quick_test
```

## ğŸš¨ Notas Importantes

- **Eval y test siempre usan el mejor modelo** disponible
- **Los datasets deben estar en la carpeta `datasets/`**
- **Los modelos se guardan en la carpeta `models/`**
- **Eval nunca usa datos de entrenamiento** (siempre datos separados)
- **Config profiles** permiten reproducibilidad completa
- **Quantum mode** en `retrain.py` preserva conocimiento existente (ver configs/retrain.yaml)
- **Query batch size** acelera evaluaciÃ³n procesando mÃºltiples queries simultÃ¡neamente

## ğŸ†˜ Troubleshooting

### "No models directory found"
```bash
python cli/train.py --dataset msmarco  # Entrena un modelo primero
```

### "No trained models found"
```bash
python cli/train.py --dataset [dataset]  # Debes tener al menos un modelo entrenado
```

### Dataset no encontrado
```bash
ls datasets/  # Verifica que el archivo existe
python cli/train.py --dataset [nombre_sin_.json]
```

### Config profile no encontrado
```bash
ls configs/  # Verifica perfiles disponibles
python cli/train.py --config-profile default  # Usa perfil vÃ¡lido
```

### Data leakage en testing
```bash
# âŒ MAL: Usa mismo conjunto que eval
python cli/test.py --domain msmarco

# âœ… BUENO: Usa datos completamente frescos
python cli/test.py --domain msmarco_fresh

# âœ… BUENO: Usa queries custom nunca vistas
python cli/test.py --queries "tu query completamente nueva"
```

### EvaluaciÃ³n lenta
```bash
# âœ… Usa optimizaciÃ³n de batch queries
python cli/eval.py --dataset msmarco --query-batch-size 8
```

### MS MARCO no disponible para test
```bash
# Si hay problemas con MS MARCO, usa dominios predefinidos
python cli/test.py --domain general  # Queries genÃ©ricas
python cli/test.py --domain medical  # Queries mÃ©dicas
```

## ğŸ“š Ejemplos de ConfiguraciÃ³n

### Crear config personalizado
```yaml
# configs/my_experiment.yaml
model:
  model_name: bert-base-uncased
  max_length: 256
  use_lora: true

training:
  epochs: 5
  batch_size: 16
  learning_rate: 0.00002

data:
  dataset: msmarco
  max_samples: 10000
```

```bash
# Usar config personalizado
python cli/train.py --config configs/my_experiment.yaml
```

### Sobrescribir config desde CLI
```bash
# Config dice epochs=5, pero queremos 10
python cli/train.py --config configs/my_experiment.yaml --epochs 10
```

## ğŸ“ JerarquÃ­a de ConfiguraciÃ³n

Prioridad (mayor a menor):
1. **CLI arguments** (--epochs 10)
2. **Config file** (--config configs/my.yaml)
3. **Config profile** (--config-profile default)
4. **Defaults** (hardcoded en cÃ³digo)

Ejemplo:
```bash
# retrain.yaml tiene quantum_mode: false
# CLI override activa quantum mode
python cli/retrain.py --config-profile retrain --quantum-mode
```
