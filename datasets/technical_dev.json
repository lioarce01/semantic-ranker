[
  {
    "query": "¿Cómo implementar autenticación JWT segura en una API REST con Node.js?",
    "positive": "Implementación JWT segura en Node.js: 1. Instalar dependencias: 'jsonwebtoken', 'bcryptjs', 'express-jwt'. 2. Crear middleware de verificación: verificar token en header Authorization, validar firma con clave secreta. 3. Endpoint login: hashear password con bcrypt, generar token con payload (userId, exp), usar HS256. 4. Refresh tokens: generar token largo duración para renovar access tokens. 5. Seguridad: usar HTTPS obligatorio, expiración corta (<15min), almacenar tokens en httpOnly cookies, implementar rate limiting, validar tokens en blacklist para logout. 6. Manejo errores: 401 para tokens inválidos/expirados, 403 para acceso denegado. 7. Librerías: passport-jwt para integración fácil, redis para token blacklist.",
    "negatives": [
      "JWT se implementa guardando tokens en localStorage del navegador.",
      "Los tokens JWT no necesitan expiración ya que son seguros por diseño.",
      "La autenticación JWT no requiere HTTPS para funcionar correctamente."
    ]
  },
  {
    "query": "¿Cuáles son las mejores prácticas para diseñar una arquitectura de microservicios?",
    "positive": "Arquitectura microservicios: 1. Descomposición por dominio (bounded contexts DDD). 2. Comunicación: APIs REST/gRPC, mensajería asíncrona (RabbitMQ, Kafka). 3. Base datos: database por servicio (PostgreSQL, MongoDB según necesidades). 4. Service discovery: Consul, Eureka. 5. API Gateway: Kong, Zuul para enrutamiento, autenticación, rate limiting. 6. Configuración centralizada: Spring Cloud Config, Consul. 7. Observabilidad: logs centralizados (ELK), métricas (Prometheus), tracing (Jaeger). 8. Resiliencia: circuit breakers (Hystrix), retries, timeouts. 9. Deployment: contenedores Docker, orquestación Kubernetes. 10. CI/CD: pipelines automatizados, blue-green deployments. 11. Contratos: OpenAPI/Swagger, consumer-driven contracts. 12. Equipos: team por servicio, autonomía técnica.",
    "negatives": [
      "Los microservicios requieren que todos los servicios compartan la misma base de datos.",
      "La arquitectura de microservicios elimina completamente la necesidad de coordinación entre equipos.",
      "Los microservicios no requieren estrategias especiales de deployment y monitoreo."
    ]
  },
  {
    "query": "¿Cómo optimizar consultas SQL en PostgreSQL para alto rendimiento?",
    "positive": "Optimización PostgreSQL: 1. Análisis: EXPLAIN (BUFFERS, ANALYZE) para ver plan de ejecución. 2. Índices: B-tree para igualdad/rangos, hash para igualdad exacta, GIN/GIST para arrays/texto completo, partial para subsets. 3. Particionamiento: RANGE por fecha, HASH por ID, LIST por categorías. 4. Consultas: evitar SELECT *, usar LIMIT, joins eficientes (INNER vs LEFT), EXISTS vs IN. 5. Estadísticas: ANALYZE para actualizar estadísticas, aumentar default_statistics_target. 6. Configuración: shared_buffers (25% RAM), work_mem, maintenance_work_mem, checkpoint_segments. 7. Pooling: PgBouncer para conexiones. 8. Cache: query result cache, aplicación-level caching (Redis). 9. Vacuum: autovacuum tuning, manual vacuum full si necesario. 10. Monitoring: pg_stat_statements, pg_stat_activity, slow query log.",
    "negatives": [
      "PostgreSQL no requiere índices adicionales ya que optimiza automáticamente todas las consultas.",
      "Las consultas SELECT * son igual de eficientes que consultas específicas en PostgreSQL.",
      "PostgreSQL no necesita configuración específica para alto rendimiento."
    ]
  },
  {
    "query": "¿Cómo implementar un sistema de cache distribuido con Redis?",
    "positive": "Cache distribuido Redis: 1. Arquitectura: Redis Cluster (sharding automático, alta disponibilidad) o Redis Sentinel (failover). 2. Patrones: cache-aside (lazy loading), write-through, write-behind. 3. Estrategias: TTL para expiración automática, LRU eviction, cache warming. 4. Serialización: JSON para objetos complejos, MessagePack para performance. 5. Consistencia: eventual consistency aceptable, invalidación manual/cache busting. 6. Monitoreo: Redis INFO, latency monitoring, hit/miss ratios. 7. Persistence: RDB snapshots + AOF para durabilidad. 8. Seguridad: autenticación password, TLS encryption, firewalls. 9. Scaling: Redis Cluster para horizontal scaling, connection pooling (redis-py). 10. Casos uso: session storage, API responses, computed results, rate limiting.",
    "negatives": [
      "Redis requiere que todos los datos sean serializados como strings únicamente.",
      "Redis no soporta expiración automática de claves cacheadas.",
      "Redis no puede escalar horizontalmente para manejar grandes volúmenes de datos."
    ]
  },
  {
    "query": "¿Cuáles son las mejores prácticas para escribir pruebas unitarias en Python?",
    "positive": "Pruebas unitarias Python: 1. Framework: pytest > unittest (fixtures, parametrization, plugins). 2. Estructura: tests/ paralelo a src/, naming test_*.py, test_* functions. 3. AAA: Arrange (setup), Act (execute), Assert (verify). 4. Fixtures: usar @pytest.fixture para setup común, scope (function, class, module). 5. Mocks: unittest.mock (MagicMock, patch) para dependencias externas. 6. Parametrization: @pytest.mark.parametrize para casos múltiples. 7. Coverage: pytest-cov, objetivo >80%, excluir __init__.py. 8. Assertions: usar matchers específicos (pytest.raises, approx para floats). 9. Isolation: cada test independiente, no compartir estado. 10. CI/CD: ejecutar en pipeline, fallar si coverage baja. 11. Dobles: dummy, stub, spy, mock, fake según necesidad. 12. TDD: escribir tests antes del código.",
    "negatives": [
      "Las pruebas unitarias deben probar la integración completa del sistema.",
      "Es aceptable que las pruebas unitarias compartan estado entre sí.",
      "Las pruebas unitarias no requieren mocks para dependencias externas."
    ]
  },
  {
    "query": "¿Cómo implementar un pipeline de CI/CD con GitHub Actions?",
    "positive": "GitHub Actions CI/CD: 1. Workflows: .github/workflows/, YAML, triggers (push, PR, schedule). 2. Jobs: paralelo o secuencial, runs-on (ubuntu-latest, windows, macOS). 3. Steps: uses para actions oficiales, run para comandos. 4. Matrix: testing múltiples versiones Python/Node. 5. Caching: dependencies, build artifacts. 6. Secrets: API keys, tokens en repository secrets. 7. Artifacts: upload/download build outputs. 8. Environments: staging, production con approvals. 9. Self-hosted runners: para hardware específico. 10. Composite actions: reusable workflows. 11. Security: code scanning, dependency review, secret scanning. 12. Monitoreo: workflow status, notifications Slack/Discord. Ejemplo básico: checkout → setup Python → install deps → run tests → build → deploy.",
    "negatives": [
      "GitHub Actions solo funciona con repositorios públicos de GitHub.",
      "Los workflows de GitHub Actions no pueden ejecutar comandos del sistema operativo.",
      "GitHub Actions requiere que todos los jobs se ejecuten en paralelo."
    ]
  },
  {
    "query": "¿Cómo diseñar una API RESTful siguiendo las mejores prácticas?",
    "positive": "API RESTful design: 1. Recursos: sustantivos, no verbos (/users, /orders/123). 2. HTTP methods: GET (read), POST (create), PUT/PATCH (update), DELETE. 3. Status codes: 200 OK, 201 Created, 400 Bad Request, 401 Unauthorized, 404 Not Found, 500 Internal Error. 4. Versioning: /v1/users, header Accept: application/vnd.api+json; version=1.0. 5. Filtering/Sorting/Pagination: ?status=active&sort=name&limit=10&offset=20. 6. HATEOAS: links en responses para navegación. 7. Content negotiation: Accept/Content-Type headers (JSON, XML). 8. Error handling: consistent error format, no stack traces. 9. Security: HTTPS, authentication (JWT, OAuth), rate limiting, input validation. 10. Documentation: OpenAPI/Swagger. 11. Caching: ETags, Cache-Control headers. 12. Idempotency: POST no idempotent, PUT sí.",
    "negatives": [
      "Las APIs RESTful deben usar únicamente el método GET para todas las operaciones.",
      "Los códigos de estado HTTP son opcionales en el diseño de APIs.",
      "Las APIs RESTful requieren que todos los recursos estén anidados jerárquicamente."
    ]
  },
  {
    "query": "¿Cómo implementar monitoreo y logging distribuido en microservicios?",
    "positive": "Monitoreo microservicios: 1. Logging centralizado: ELK stack (Elasticsearch, Logstash, Kibana), Fluentd. 2. Estructura logs: JSON format, correlation ID, timestamp, level, message, context. 3. Métricas: Prometheus + Grafana, custom metrics (response time, error rate, throughput). 4. Health checks: endpoints /health, /metrics, circuit breaker status. 5. Tracing distribuido: Jaeger, Zipkin, OpenTelemetry (trace ID through services). 6. Alerting: Prometheus Alertmanager, PagerDuty, Slack notifications. 7. Dashboards: Grafana panels, business metrics vs technical metrics. 8. APM: New Relic, Datadog, Dynatrace. 9. Log aggregation: structured logging, log levels (ERROR, WARN, INFO, DEBUG). 10. Correlation: request ID through all services, baggage propagation. 11. SLOs/SLIs: service level objectives, error budgets.",
    "negatives": [
      "Los microservicios no requieren logging centralizado ya que cada servicio es independiente.",
      "El tracing distribuido solo es necesario en sistemas con alta carga de trabajo.",
      "Los health checks no son importantes en arquitecturas de microservicios."
    ]
  }
]
