# Query Graph Neural Reranking Configuration
# Novel research approach: First GNN-based reranker using query graphs
# Config based on quantum_base_resonance_5k_2e_optimized (NDCG 0.78 avg)

model:
  model_name: bert-base-uncased
  max_length: 256
  use_lora: true
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.1

training:
  epochs: 3
  batch_size: 8   # Reduced for 32GB RAM stability
  learning_rate: 2.0e-05  # 2e-5, proven optimal from quantum model
  weight_decay: 0.01
  warmup_ratio: 0.1
  max_grad_norm: 1.0
  loss_function: bce
  eval_steps: 100
  logging_steps: 50
  save_strategy: best
  gradient_accumulation_steps: 8  # Effective batch = 64 (same as before, but more stable)
  fp16: true

data:
  dataset: superset_comprehensive  # Same as quantum_base_resonance_5k_2e_optimized
  max_samples: null  # All 5503 samples (set to number to limit, null for all)
  train_samples: null  # Training samples to use (null for all available)
  val_samples: null  # Validation samples to use (null for all available)
  test_samples: null  # Test samples to use (null for all available)
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  negative_sampling: hard  # Hard negatives crucial for performance
  num_negatives: 2

gnn:
  gnn_mode: true
  embedding_model: all-mpnet-base-v2  # 768-dim semantic embeddings
  similarity_threshold: 0.65  # Slightly lower for more edges (was 0.7)
  max_neighbors: 8   # Reduced for memory efficiency (was 10)
  max_queries_for_graph: 2500  # Increased to 2500 (optimal for 32GB RAM)
  graph_batch_size: 150  # Smaller chunks for more stability
  gnn_hidden_dim: 192  # Reduced for memory (was 256)
  gnn_output_dim: 96   # Reduced for memory (was 128)
  gnn_dropout: 0.15    # Increased dropout for regularization
  lambda_contrastive: 0.1  # Weight for contrastive loss in query space
  lambda_rank: 0.05  # Weight for GNN ranking loss
  temperature: 0.07  # Temperature for InfoNCE contrastive loss

quantum:
  quantum_mode: false  # Disable quantum for QG-Rerank

evaluation:
  metrics:
    - ndcg@10
    - ndcg@20
    - mrr@10
    - map@10
  batch_size: 32
  num_samples: null
